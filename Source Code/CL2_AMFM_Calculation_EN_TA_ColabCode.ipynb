{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CL2 AMFM Calculation_EN_TA_ColabCode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcR7jLYw8HIH",
        "outputId": "479f7484-c02a-4fcb-ccaa-760e57140031"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 2.7.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyrpibuNdqex"
      },
      "source": [
        "VERBOSE_LEVEL = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxVbY3XK8iGg",
        "outputId": "7c2ed1c0-a45e-4561-a171-dd83670d7721"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4Lb4ho8koG"
      },
      "source": [
        "import os\n",
        "os.chdir('/gdrive/MyDrive/AMFM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdMVJyvzcfiU"
      },
      "source": [
        "# Common python modules\n",
        "import os\n",
        "import sys\n",
        "import string\n",
        "import json\n",
        "import argparse\n",
        "import signal\n",
        "import pickle as pickle\n",
        "from lm import ArpaLM\n",
        "import unicodedata\n",
        "import joblib as jlib\n",
        "from functools import partial\n",
        "\n",
        "try:\n",
        "    import numpy as np\n",
        "except:\n",
        "    print(\"Error: Requires numpy from http://www.numpy.org/. Have you installed numpy?\")\n",
        "    sys.exit()\n",
        "\n",
        "\n",
        "try:\n",
        "    from sklearn.externals import joblib\n",
        "except:\n",
        "    print(\"Error: Requires sklearn from http://scikit-learn.org/. Have you installed scikit?\")\n",
        "    sys.exit()\n",
        "\n",
        "\n",
        "try:\n",
        "    from scipy.spatial.distance import cosine\n",
        "except:\n",
        "    print(\"Error: Requires scipy from http://scipy.org/. Have you installed scipy?\")\n",
        "    sys.exit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LJYDTgkfDN4",
        "outputId": "e04d760e-3835-4b7c-d669-71803d1f178f"
      },
      "source": [
        "models_dir = os.getcwd() + '/models/'\n",
        "print(models_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/AMFM/models/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-tUVvtAfbV7"
      },
      "source": [
        "# Global variables\n",
        "WORD_TOKENS = ['en', 'in', 'ko', 'hi', 'my', 'bn', 'ml', 'si', 'ta', 'te', 'ur', 'ru', 'km']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJKcv3J1fqzZ"
      },
      "source": [
        "CONF_VALUES = {\n",
        "    'EN_HI_MULTIMODAL':\n",
        "        {\n",
        "            'ROOT_DIR': 'EN_HI_MULTIMODAL/en_hi_multimodal',\n",
        "            'en': {\n",
        "                'NUM_TRAIN_SENT': 20000,  # Number of sentences used during training\n",
        "                'FULL_AM_SIZE': 2500,  # Max size of the trained AM model\n",
        "                'OPT_AM_SIZE': 1500,  # Optimal value for the trained AM model\n",
        "                'NGRAM_ORDER': 1,  # Order the FM score calculation\n",
        "                'NUM_FOLD': 0,  # Fold used to train the models\n",
        "                'PREFIX_AM_FM': 'train',  # Prefix for the AM-FM models\n",
        "                'ALPHA': 0.5  # Interpolation value for AM-FM\n",
        "            },\n",
        "            'hi': {\n",
        "                'NUM_TRAIN_SENT': 20000,  # Number of sentences used during training\n",
        "                'FULL_AM_SIZE': 2500,  # Max size of the trained AM model\n",
        "                'OPT_AM_SIZE': 150,  # Optimal value for the trained AM model\n",
        "                'NGRAM_ORDER': 1,  # Order the FM score calculation\n",
        "                'NUM_FOLD': 0,  # Fold used to train the models\n",
        "                'PREFIX_AM_FM': 'train',  # Prefix for the AM-FM models\n",
        "                'ALPHA': 0.5  # Interpolation value for AM-FM\n",
        "            },\n",
        "        },\n",
        "    'WAT2019_EN_HI':\n",
        "        {\n",
        "            'ROOT_DIR': 'WAT2019_EN_HI/en_hi',\n",
        "            'hi': {\n",
        "                'NUM_TRAIN_SENT': 20000,  # Number of sentences used during training\n",
        "                'FULL_AM_SIZE': 2500,  # Max size of the trained AM model\n",
        "                'OPT_AM_SIZE': 2000,  # Optimal value for the trained AM model\n",
        "                'NGRAM_ORDER': 3,  # Order the FM score calculation\n",
        "                'NUM_FOLD': 0,  # Fold used to train the models\n",
        "                'PREFIX_AM_FM': 'train',  # Prefix for the AM-FM models\n",
        "                'ALPHA': 0.5  # Interpolation value for AM-FM\n",
        "            },\n",
        "            'en': {\n",
        "                'NUM_TRAIN_SENT': 20000,  # Number of sentences used during training\n",
        "                'FULL_AM_SIZE': 2500,  # Max size of the trained AM model\n",
        "                'OPT_AM_SIZE': 500,  # Optimal value for the trained AM model\n",
        "                'NGRAM_ORDER': 2,  # Order the FM score calculation\n",
        "                'NUM_FOLD': 0,  # Fold used to train the models\n",
        "                'PREFIX_AM_FM': 'train',  # Prefix for the AM-FM models\n",
        "                'ALPHA': 0.5  # Interpolation value for AM-FM\n",
        "            },\n",
        "        },\n",
        "        'WAT2019_EN_TA':\n",
        "        {\n",
        "            'ROOT_DIR': 'WAT2019_EN_TA/en_ta',\n",
        "            'ta': {\n",
        "                'NUM_TRAIN_SENT': 15000,  # Number of sentences used during training\n",
        "                'FULL_AM_SIZE': 2500,  # Max size of the trained AM model\n",
        "                'OPT_AM_SIZE': 2000,  # Optimal value for the trained AM model\n",
        "                'NGRAM_ORDER': 3,  # Order the FM score calculation\n",
        "                'NUM_FOLD': 0,  # Fold used to train the models\n",
        "                'PREFIX_AM_FM': 'train',  # Prefix for the AM-FM models\n",
        "                'ALPHA': 0.5  # Interpolation value for AM-FM\n",
        "            },\n",
        "            'en': {\n",
        "                'NUM_TRAIN_SENT': 20000,  # Number of sentences used during training\n",
        "                'FULL_AM_SIZE': 2500,  # Max size of the trained AM model\n",
        "                'OPT_AM_SIZE': 250,  # Optimal value for the trained AM model\n",
        "                'NGRAM_ORDER': 1,  # Order the FM score calculation\n",
        "                'NUM_FOLD': 0,  # Fold used to train the models\n",
        "                'PREFIX_AM_FM': 'train',  # Prefix for the AM-FM models\n",
        "                'ALPHA': 0.5  # Interpolation value for AM-FM\n",
        "            },\n",
        "        },\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq4tdAAuf9ii"
      },
      "source": [
        "sc = set(['-', \"'\", '%'])\n",
        "to_remove = ' '.join([c for c in string.punctuation if c not in sc])\n",
        "table = dict((ord(char), u' ') for char in to_remove)\n",
        "\n",
        "\n",
        "sc = set([',', '!', '?', '.'])\n",
        "to_separate = ''.join([c for c in string.punctuation if c not in sc])\n",
        "table_separate = dict((ord(char), u' ' + char) for char in to_separate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcSBuWQRgFCY"
      },
      "source": [
        "#tbl = dict((char, u' ') for char in range(sys.maxunicode) if unicodedata.category(chr(char)).startswith('P'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVBhQGHzgh05"
      },
      "source": [
        "# Implementation of the vector space model\n",
        "class VSM:\n",
        "    def __init__(self, model_file, size_am):\n",
        "        self.am = None\n",
        "        self.vectorizer = None\n",
        "        self.load(model_file)\n",
        "        self.am_components = self.am[:, 0:size_am]\n",
        "        self.cache_refvectors = dict()\n",
        "\n",
        "    # Function to get the distance between a set of reference and test sentences\n",
        "    def search(self, ref_sentence, test_sentence):\n",
        "        \"\"\" search for documents that match based on a list of terms \"\"\"\n",
        "        reference_vector = self.vectorizer.transform([ref_sentence])\n",
        "        target_vector = self.vectorizer.transform([test_sentence])\n",
        "\n",
        "        if ref_sentence not in self.cache_refvectors:\n",
        "            ref = reference_vector.dot(self.am_components)\n",
        "            self.cache_refvectors[ref_sentence] = ref\n",
        "        else:\n",
        "            ref = self.cache_refvectors[ref_sentence]\n",
        "\n",
        "        if test_sentence not in self.cache_refvectors:\n",
        "            tgt = target_vector.dot(self.am_components)\n",
        "            self.cache_refvectors[test_sentence] = tgt\n",
        "        else:\n",
        "            tgt = self.cache_refvectors[test_sentence]\n",
        "\n",
        "        return max(0.0, 1.0 - cosine(ref, tgt))  # Avoid sending negative distances\n",
        "\n",
        "    # Load models\n",
        "    def load(self, name_model):\n",
        "        # WAT2019: added because incompatibilities when reading old files created using python2\n",
        "        try:\n",
        "            self.am = jlib.load(name_model + '.h5')\n",
        "            print(\"Loading using jlib\")\n",
        "            print(\"Data type of AM model is \")\n",
        "            print(type(self.am))\n",
        "            print(self.am.shape)\n",
        "        except:\n",
        "            try:\n",
        "                print(\"Loading Python 2.7 compatible model using joblib/sklearn 0.17.1\")\n",
        "                self.am = joblib.load(name_model + '.h5')\n",
        "                print(\"Data type of AM model is \")\n",
        "                print(type(self.am))\n",
        "            except:\n",
        "                file_h = open(name_model + '.h5', \"rb\")\n",
        "                self.am = pickle.load(name_model + '.h5')\n",
        "                print(\"Loading using pickle\")\n",
        "                print(\"Data type of AM model is \")\n",
        "                print(type(self.am))\n",
        "                file_h.close()\n",
        "\n",
        "        # WAT2019: added because incompatibilities when reading old files created using python2\n",
        "        try:\n",
        "            self.vectorizer = jlib.load(name_model + '.dic')\n",
        "        except:\n",
        "            try:\n",
        "                self.vectorizer = joblib.load(name_model + '.dic')\n",
        "\n",
        "            except:\n",
        "                file_h = open(name_model + '.dic', \"rb\")\n",
        "                self.vectorizer = pickle.load(file_h)\n",
        "                file_h.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQYI9B7nlH6w"
      },
      "source": [
        "class calcScoresAMFM:\n",
        "    def __init__(self, dataset, lang='en', am=True, fm=True):\n",
        "        # Load configuration variables for language\n",
        "        self.DATASET_DIR = CONF_VALUES[dataset]['ROOT_DIR']\n",
        "        self.FULL_AM_SIZE = CONF_VALUES[dataset][lang]['FULL_AM_SIZE']\n",
        "        self.OPT_AM_SIZE = CONF_VALUES[dataset][lang]['OPT_AM_SIZE']\n",
        "        self.NUM_TRAINING_SIZE = CONF_VALUES[dataset][lang]['NUM_TRAIN_SENT']\n",
        "        self.PREFIX_AM_FM = CONF_VALUES[dataset][lang]['PREFIX_AM_FM']\n",
        "        self.NGRAM_ORDER = CONF_VALUES[dataset][lang]['NGRAM_ORDER']\n",
        "        self.NUM_FOLD = CONF_VALUES[dataset][lang]['NUM_FOLD']\n",
        "        self.alpha = CONF_VALUES[dataset][lang]['ALPHA']\n",
        "        self.lang = lang\n",
        "        self.am = am\n",
        "        self.fm = fm\n",
        "        self.cache_lm = dict()  # Store previously calculated n-gram values for speed\n",
        "\n",
        "        if self.am is True:\n",
        "            # Check that the AM models exist\n",
        "            am_full_matrix = models_dir + '/' + self.DATASET_DIR + '/' + self.PREFIX_AM_FM + '.' + lang + '.' \\\n",
        "                             + str(self.NUM_TRAINING_SIZE) + \\\n",
        "                             '.' + str(self.FULL_AM_SIZE) + '.' + str(self.NUM_FOLD)\n",
        "            if not os.path.isfile(am_full_matrix + '.h5') or not os.path.isfile(am_full_matrix + '.dic'):\n",
        "                print ('******* ERROR: files: ' + am_full_matrix + '.h5 or ' + am_full_matrix + '.dic does not exists.')\n",
        "                exit()\n",
        "            elif os.path.getsize(am_full_matrix + '.h5') == 0 or os.path.getsize(am_full_matrix + '.dic') == 0:\n",
        "                print ('******* ERROR: Check if files: ' + am_full_matrix + '.h5 or ' + am_full_matrix +\n",
        "                       '.dic are not empty.')\n",
        "                exit()\n",
        "\n",
        "        print('Starting loading models for language %s ...' % (lang))\n",
        "        if self.am is True:\n",
        "            # Load the models\n",
        "            print('Loading AM model... for size' + str(self.OPT_AM_SIZE))\n",
        "            print(type(am_full_matrix))\n",
        "            self.vs = VSM(am_full_matrix, self.OPT_AM_SIZE)\n",
        "\n",
        "        if self.fm is True:\n",
        "            # Check that the LM model exists\n",
        "            lm_model = models_dir + '/' + self.DATASET_DIR + '/' + self.PREFIX_AM_FM + '.' + lang + '.' + str(self.NGRAM_ORDER) + '.lm'\n",
        "            if not os.path.exists(lm_model):\n",
        "                print(\"******* ERROR: LM file \" + lm_model + ' does not exists.')\n",
        "                exit()\n",
        "            elif os.path.getsize(lm_model) == 0:\n",
        "                print(\"******* ERROR: LM file \" + lm_model + ' is empty.')\n",
        "                exit()\n",
        "            print('Loading FM model...' + str(self.NGRAM_ORDER))\n",
        "            print(lm_model)\n",
        "            self.lm = ArpaLM(lm_model)\n",
        "\n",
        "        print('Finished loading models for language %s ...' % (lang))\n",
        "\n",
        "    # Perform basic pre-processing applied during training\n",
        "    def doProcessFromStrings(self, ref, pred):\n",
        "        ref = self.preProcess(ref, self.lang)\n",
        "        pred = self.preProcess(pred, self.lang)\n",
        "        return ref, pred\n",
        "\n",
        "    def remove_punctuation(self, word):\n",
        "        return \"\".join(char for char in word if not unicodedata.category(char).startswith('P'))\n",
        "\n",
        "    # Pre-Processing for each sentence. In the case of languages different to English we perform tokenization\n",
        "    # per character\n",
        "    def preProcess(self, s, lang):\n",
        "        if len(s) == 0:  # To avoid empty lines\n",
        "            return '_EMPTY_'\n",
        "        #print(s)\n",
        "        #print(type(s))\n",
        "        # Perform some normalization for UTF-8\n",
        "        s = unicodedata.normalize('NFKC', s)\n",
        "\n",
        "        # Remove some punctuation\n",
        "        s = s.translate(table)\n",
        "        s = s.translate(table_separate)\n",
        "\n",
        "        # Translation for UTF-8 punctuation characters\n",
        "        #s = s.translate(tbl)\n",
        "\n",
        "        # Tokenization by characters except for those in the list\n",
        "        if lang not in WORD_TOKENS:\n",
        "            tokens = [' '.join([c for c in list(word.strip())]) for word in s.split()]\n",
        "        else:\n",
        "            tokens = s.split()\n",
        "\n",
        "        s = ' '.join(tokens).lower()\n",
        "        return s\n",
        "\n",
        "    # Function to calculate the FM metric using language models\n",
        "    def calculateFMMetric(self, ref, tst):\n",
        "        if self.lang not in WORD_TOKENS:\n",
        "            ref = ' '.join(list(ref.strip()))\n",
        "            tst = ' '.join(list(tst.strip()))\n",
        "\n",
        "        sent = '<s> ' + ref.strip() + ' </s>'\n",
        "        if VERBOSE_LEVEL > 1:\n",
        "            print('REF: ' + sent)\n",
        "        aWords = sent.split()\n",
        "        num_words_ref = len(aWords) - 2\n",
        "        prob_ref = 0.0\n",
        "        # Calculates the log-prob for the different n-grams\n",
        "        for i in range(1, len(aWords)):\n",
        "            words = aWords[max(0, i - self.NGRAM_ORDER + 1):i + 1]\n",
        "            ngram = ' '.join(words)\n",
        "            # Try to speed calculation by using cache values\n",
        "            try:\n",
        "                val = self.cache_lm[ngram]\n",
        "                prob_ref += self.cache_lm[ngram]\n",
        "            except:\n",
        "                val = self.lm.score(tuple(words))\n",
        "                self.cache_lm[ngram] = val\n",
        "                prob_ref += val\n",
        "            if VERBOSE_LEVEL > 2:\n",
        "                print('words: ' + ngram + ' value: ' + str(val))\n",
        "\n",
        "        sent = '<s> ' + tst.strip() + ' </s>'\n",
        "        if VERBOSE_LEVEL > 1:\n",
        "            print('SUB: ' + sent)\n",
        "        aWords = sent.split()\n",
        "        num_words_tst = len(aWords) - 2\n",
        "        prob_tst = 0.0\n",
        "        # Calculates the log-prob for the different n-grams\n",
        "        for i in range(1, len(aWords)):\n",
        "            words = aWords[max(0, i - self.NGRAM_ORDER + 1):i + 1]\n",
        "            ngram = ' '.join(words)\n",
        "            # Try to speed calculation by using cache values\n",
        "            try:\n",
        "                val = self.cache_lm[ngram]\n",
        "                prob_tst += self.cache_lm[ngram]\n",
        "            except:\n",
        "                val = self.lm.score(tuple(words))\n",
        "                self.cache_lm[ngram] = val\n",
        "                prob_tst += val\n",
        "            if VERBOSE_LEVEL > 2:\n",
        "                print('words: ' + ngram + ' value: ' + str(val))\n",
        "\n",
        "        # Calculate the scaled probability\n",
        "        prob_ref = np.exp(prob_ref / num_words_ref)\n",
        "        prob_tst = np.exp(prob_tst / num_words_tst)\n",
        "        if VERBOSE_LEVEL > 0:\n",
        "            print('LM -> REF: ' + str(prob_ref) + ' SUB: ' + str(prob_tst))\n",
        "        return max(0.0, min(prob_tst, prob_ref)/max(prob_tst, prob_ref))\n",
        "\n",
        "    # Functionality to calculate the AM score using monolingual SVM\n",
        "    def calculateAMMetric(self, ref, pred):\n",
        "        return self.vs.search(ref, pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nbwsY1uolnK",
        "outputId": "4e765782-0611-4ec4-d382-760d19104fcb"
      },
      "source": [
        "#instance for the above classes\n",
        "targetlang = 'ta'\n",
        "targetdataset= 'WAT2019_EN_TA'\n",
        "cs = calcScoresAMFM(dataset=targetdataset, lang=targetlang, am=True, fm=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting loading models for language ta ...\n",
            "Loading AM model... for size2000\n",
            "<type 'str'>\n",
            "Loading using jlib\n",
            "Data type of AM model is \n",
            "<class 'sklearn.externals.joblib.numpy_pickle_compat.ZNDArrayWrapper'>\n",
            "Loading Python 2.7 compatible model using joblib/sklearn 0.17.1\n",
            "Data type of AM model is \n",
            "<class 'numpy.matrix'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/base.py:253: UserWarning: Trying to unpickle estimator CountVectorizer from version pre-0.18 when using version 0.20.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading FM model...3\n",
            "/gdrive/MyDrive/AMFM/models//WAT2019_EN_TA/en_ta/train.ta.3.lm\n",
            "/gdrive/MyDrive/AMFM/models//WAT2019_EN_TA/en_ta/train.ta.3.lm\n",
            "Finished loading models for language ta ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHXPZFmPt072"
      },
      "source": [
        "def processSubmission(target, submission, cs, fm, am):\n",
        "        (target, submission) = cs.doProcessFromStrings(ref=target, pred=submission)\n",
        "        if VERBOSE_LEVEL > 0:\n",
        "            print('POST_REF: ' + target + ' SUB: ' + submission)\n",
        "\n",
        "        if len(target) > 0 and len(submission) > 0:\n",
        "            res_fm = -1.0\n",
        "            if fm is True:\n",
        "                res_fm = cs.calculateFMMetric(target, submission)\n",
        "\n",
        "            res_am = -1.0\n",
        "            if am is True:\n",
        "                res_am = min(1.0, cs.calculateAMMetric(target, submission))\n",
        "\n",
        "            res_am_fm = -1.0\n",
        "            if am is True and fm is True:\n",
        "                res_am_fm = cs.alpha * res_am + (1.0 - cs.alpha) * res_fm\n",
        "\n",
        "            return (res_am_fm, res_am, res_fm, cs.alpha)\n",
        "        else:\n",
        "            return (0.0, 0.0, 0.0, cs.alpha)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsvG21its1PY",
        "outputId": "83c0f479-9311-44b7-d8aa-ccc731da867a"
      },
      "source": [
        "processSubmission(unicode(\"காலை வணக்கம்\",\"utf-8\"),unicode(\"மாலை  வணக்கம்\",\"utf-8\"),cs,True,True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6564248247632654, 0.7500000000000002, 0.5628496495265305, 0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRtEoXYW1w8v"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAFEz4pu17Xt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDMnose5vh2_"
      },
      "source": [
        "candidateFile = \"/gdrive/MyDrive/AMFM/EnTa/microsoft_en_ta_results.ta\"\n",
        "referenceFile =\"/gdrive/MyDrive/AMFM/EnTa/corpus.bcn.dev.ta\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dgcPwQ8P7_o"
      },
      "source": [
        "import pandas as pd \n",
        "dict = {'ReferenceTxt':['sample text'], \n",
        "        'CandidateTxt':['sample translation'], \n",
        "        'res_am_fm':[0] ,\n",
        "        'res_am':[0] ,\n",
        "        'res_fm':[0] ,\n",
        "        'res_alpha':[0]         \n",
        "       }\n",
        "resultDf = pd.DataFrame(dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAJrzrA0vpoV"
      },
      "source": [
        "with open(referenceFile) as refFile,open(candidateFile) as canFile: \n",
        "    s_reference = refFile.readline()\n",
        "    s_candidate = canFile.readline()\n",
        "    count = 1\n",
        "    while s_candidate :\n",
        "      res_am_fm,res_am,res_fm,res_alpha= processSubmission(unicode(s_reference,\"utf-8\"),unicode(s_candidate,\"utf-8\"),cs,True,True)\n",
        "      resultDf.loc[len(resultDf.index)] = [s_reference,s_candidate,res_am_fm,res_am,res_fm,res_alpha]\n",
        "      s_reference = refFile.readline()\n",
        "      s_candidate = canFile.readline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDA5Tuo8SYBj"
      },
      "source": [
        "resultDf.to_excel(\"output_ta.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRoB-83i3P_B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}